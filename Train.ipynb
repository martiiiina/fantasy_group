{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common import sigmoid\n",
    "from mie import build_k_indices, cross_validation, subsample_class, build_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4d299",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gamma = 0.1\n",
    "batch_size = 128\n",
    "num_batches = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b00692",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaac3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = np.load(\"processed/x_train.npy\")\n",
    "x_test_norm = np.load(\"processed/x_test.npy\")\n",
    "y_train = np.load(\"processed/y_train.npy\")\n",
    "test_ids = np.load(\"processed/test_ids.npy\")\n",
    "train_ids = np.load(\"processed/train_ids.npy\")\n",
    "\n",
    "y_train = (y_train + 1) / 2  # from -1/1 to 0/1\n",
    "\n",
    "# Add bias term to X (column of 1)\n",
    "x_train_norm = np.hstack([np.ones((x_train_norm.shape[0], 1)), x_train_norm])\n",
    "x_test_norm = np.hstack([np.ones((x_test_norm.shape[0], 1)), x_test_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75fab0",
   "metadata": {},
   "source": [
    "Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a145108",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm, y_train = subsample_class(x_train_norm, y_train, target_ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e776c2",
   "metadata": {},
   "source": [
    "Polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae70b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = []\n",
    "\n",
    "degree = 2\n",
    "\n",
    "for col in range(x_train_norm.shape[1]):\n",
    "    phi = build_poly(x_train_norm[:, col], degree)  # shape (N, degree+1)\n",
    "    X_poly.append(phi[:, 1:])  # saltiamo la colonna di 1 per non duplicare il bias\n",
    "\n",
    "# Concateno tutte le espansioni colonna per colonna\n",
    "X_poly = np.concatenate(X_poly, axis=1)\n",
    "\n",
    "# Aggiungo una colonna di 1 per il bias (una sola volta)\n",
    "X_poly = np.hstack([np.ones((X_poly.shape[0], 1)), X_poly])\n",
    "\n",
    "\n",
    "X_test_poly = []\n",
    "\n",
    "for col in range(x_test_norm.shape[1]):\n",
    "    phi = build_poly(x_test_norm[:, col], degree)\n",
    "    X_test_poly.append(phi[:, 1:])  # salta il bias interno\n",
    "\n",
    "X_test_poly = np.concatenate(X_test_poly, axis=1)\n",
    "X_test_poly = np.hstack([np.ones((X_test_poly.shape[0], 1)), X_test_poly])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a68d3",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold=5\n",
    "k_indices=build_k_indices(y_train, k_fold, seed=42)\n",
    "\n",
    "loss_val=[]\n",
    "loss_tr=[]\n",
    "ws=[]\n",
    "acc_scores=[]\n",
    "f1_scores=[]\n",
    "initial_w = np.zeros((x_train_norm.shape[1], 1))\n",
    "\n",
    "for k in range(k_fold):\n",
    "    w, loss_tr_tmp, loss_val_tmp, x_val, y_val = cross_validation(y_train, x_train_norm, \n",
    "                                                                  k_indices, k, initial_w, \n",
    "                                                                  max_iters = 4000, gamma = gamma, \n",
    "                                                                  lambda_ = 0)\n",
    "    best_val_loss = np.min(loss_val_tmp)\n",
    "    loss_val.append(best_val_loss)\n",
    "    ws.append(w)\n",
    "\n",
    "    plt.plot(loss_tr_tmp, label='Training Loss')\n",
    "    plt.plot(loss_val_tmp, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss per Epoch for fold {k+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "   \n",
    "w_best=np.mean(ws, axis=0)\n",
    "gen_err = np.mean(loss_val)\n",
    "\n",
    "print(\"Generalization error: \", gen_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de0883",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = sigmoid(x_test_norm @ w_best)\n",
    "y_pred = np.where(y_pred_prob >= 0.5, 1, -1)\n",
    "\n",
    "create_csv_submission(test_ids, y_pred, 'Train_poly2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
